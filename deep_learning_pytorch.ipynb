{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTzkBYHg/Ei84qrV4j8qxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fist2/Deep-Learning-Pytorch/blob/main/deep_learning_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.tensor([1,2,3])\n",
        "b = torch.tensor([[4],\n",
        "                 [5],\n",
        "                 [6]])\n",
        "\n",
        "print(a@b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kztcSgqEg5F",
        "outputId": "97f0930a-6bc1-4923-b780-4afa1fb59200"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "temperature = torch.tensor([[70,72,75], [68,69,40]])\n",
        "adjustment = torch.tensor([[2,2,2], [2,2,2]])\n",
        "\n",
        "print(temperature + adjustment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7VzXLCJJRZL",
        "outputId": "c9fa3f10-1077-46e8-cdb5-38977a5084ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[72, 74, 77],\n",
            "        [70, 71, 42]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "my_list = torch.tensor([[1,2,3], [4,5,6]])\n",
        "print(my_list.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SXqMnXZnKf2u",
        "outputId": "96514b01-65a0-4dc1-bea5-bc68e65f7e97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])\n",
        "linear_layer = nn.Linear(3, 2)\n",
        "output_tensor = linear_layer(input_tensor)\n",
        "print(output_tensor)\n",
        "print(linear_layer.weight)\n",
        "print(linear_layer.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Eq6iY0jcOBBs",
        "outputId": "cb0f81ca-86a2-460e-9fe6-aa818a9c6069"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4156, -0.0906]], grad_fn=<AddmmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[-0.2047, -0.4960, -0.3816],\n",
            "        [ 0.5069, -0.4228, -0.3149]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2090, -0.1485], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "input_tensor = torch.tensor([[2001.00, 1500.00, 1700.00]])\n",
        "linear_layer = nn.Linear(in_features = 3, out_features=2)\n",
        "output = linear_layer(input_tensor)\n",
        "print(output)\n",
        "print(linear_layer.weight)\n",
        "print(linear_layer.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3grpDn67XI0k",
        "outputId": "2452587b-adad-4d8f-d346-f55d8087737d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1075.3560,    66.2317]], grad_fn=<AddmmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[-0.5593,  0.0713, -0.0372],\n",
            "        [ 0.2170, -0.0607, -0.1627]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2482, -0.2698], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8,4),\n",
        "    nn.Linear(4,2)\n",
        ")\n",
        "total = 0\n",
        "for parameter in model.parameters():\n",
        "  total += parameter.numel()\n",
        "print(total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmTs_qZ9byu_",
        "outputId": "c05d4a37-1968-4bdf-b5d2-72a1da62c60b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J04ptufMdJKK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}